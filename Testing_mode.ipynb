{
 "metadata": {
  "name": "",
  "signature": "sha256:2fc39389b9ae7f8989b2a8b5ef043ff416ebf8a8099d805abafa4e425570f252"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from helpers import output_csv\n",
      "from datetime import datetime\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import xgboost as xgb\n",
      "np.random.seed(4)\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.naive_bayes import BernoulliNB\n",
      "from sklearn.metrics import log_loss\n",
      "from sklearn.preprocessing import LabelEncoder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "leaderboard = False\n",
      "use_xgb = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def handle_categorical(df, target):\n",
      "    text_col = df.select_dtypes(['object']).columns\n",
      "    for col in text_col:\n",
      "        col_to_add = pd.get_dummies(df[col])\n",
      "        df = df.drop([col], axis=1)\n",
      "        nb = BernoulliNB()\n",
      "        for i, col2 in enumerate(col_to_add.columns):\n",
      "            df['%s_%s' % (col, i)] = col_to_add[col2]\n",
      "    return df\n",
      "\n",
      "def handle_nas(df):\n",
      "    \"\"\"\n",
      "    Several ways can be used to replace NAs.\n",
      "    Currently it looks like the best option is to use -1.\n",
      "    Creating variables with info about NAs seems to worsen score.\n",
      "    \"\"\"\n",
      "    for col in df.columns:\n",
      "        df[col].fillna(-1, inplace=True)\n",
      "    return df\n",
      "\n",
      "def change_vars(df):\n",
      "    \"\"\"\n",
      "    Add variable transformations here, those will be applied\n",
      "    before handle_nas and handle_categorical. The changes in confirmed\n",
      "    were tested against 3-CV XGB.\n",
      "    \"\"\"\n",
      "    # Confirmed:\n",
      "    # for col in df.columns:\n",
      "        # df[col] = np.log1p(df[col] + 0.02) if df[col].dtype != 'object' else df[col]\n",
      "    return df\n",
      "\n",
      "def run_xgboost(train, target, test=None, test_target=None,\n",
      "    leaderboard=False):\n",
      "    \"\"\"\n",
      "    Run XGBoost in both local and leaderboard mode.\n",
      "    \"\"\"\n",
      "    xgboost_params = {\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"booster\": \"gbtree\",\n",
      "        \"eval_metric\": \"logloss\",\n",
      "        \"eta\": 0.1,\n",
      "        \"base_score\": 0.761,\n",
      "        \"subsample\": 0.8,\n",
      "        \"colsample_bytree\": 0.8,\n",
      "        \"max_depth\": 10,\n",
      "        \"min_child_weight\": 0.75,\n",
      "        }\n",
      "    train = xgb.DMatrix(train, target)\n",
      "\n",
      "    if not leaderboard:\n",
      "        xgb.cv(xgboost_params, train, num_boost_round=550, nfold=5,\n",
      "               seed=0, verbose_eval=1, early_stopping_rounds=1)\n",
      "    else:\n",
      "        eval = [(train, 'Train')]\n",
      "        test = xgb.DMatrix(test)\n",
      "        clf = xgb.train(xgboost_params, train, num_boost_round=500, evals=eval)\n",
      "        return clf.predict(test)\n",
      "\n",
      "def run_sklearn(train, target, test):\n",
      "    \"\"\"\n",
      "    Run a RFC.\n",
      "    \"\"\"\n",
      "    # rfc = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
      "    rfc = LogisticRegression()\n",
      "    rfc.fit(train, target)\n",
      "    pred = rfc.predict_proba(test)[:, 1]\n",
      "    # for i, j in zip(Xtrain.columns, rfc.feature_importances_):\n",
      "        # if j < 0.001:\n",
      "            # print(i, j*100)\n",
      "    return pred"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We restrict to the first 10k entries to test.\n",
      "print(\"Start processing.\")\n",
      "start = datetime.now()\n",
      "Xtrain = pd.read_csv('train.csv')\n",
      "Xtrain = Xtrain.ix[1:25000, :]\n",
      "ytrain = Xtrain.target\n",
      "Xtrain.v56.fillna('AAAAAAAA', inplace=True)\n",
      "Xtrain.v56 = LabelEncoder().fit_transform(Xtrain.v56)\n",
      "# Try frequency count to encode v22\n",
      "# Xtrain.v22.fillna('#', inplace=True)\n",
      "# freq = dict(Xtrain.v22.value_counts())\n",
      "# Xtrain.v22 = [freq[label] for label in Xtrain.v22]\n",
      "Xtrain = Xtrain.drop(['target', 'ID', 'v107', 'v22', 'v50'], axis=1)\n",
      "\n",
      "\n",
      "\n",
      "if leaderboard:\n",
      "    Xtest = pd.read_csv('test.csv')\n",
      "    ids = Xtest.ID\n",
      "    Xtest = Xtest.drop(['ID', 'v22', 'v107'], axis=1)\n",
      "    bonus = pd.read_csv('first_level/RFC_1000est_entropy_test.csv').pred\n",
      "    Xtest = pd.concat([Xtest, bonus], axis=1)\n",
      "    bonus = pd.read_csv('first_level/LR_l1_test.csv').pred\n",
      "    bonus.name = \"pred2\"\n",
      "    Xtest = pd.concat([Xtest, bonus], axis=1)\n",
      "    bonus = pd.read_csv('first_level/LR_test.csv').pred\n",
      "    bonus.name = \"pred3\"\n",
      "    Xtest = pd.concat([Xtest, bonus], axis=1)\n",
      "    bonus = pd.read_csv('first_level/RFC_1000est_gini_test.csv').pred\n",
      "    bonus.name = \"pred4\"\n",
      "    Xtest = pd.concat([Xtest, bonus], axis=1)\n",
      "    bonus = pd.read_csv('first_level/XGB_def_params_test.csv').pred\n",
      "    bonus.name = \"pred5\"\n",
      "    Xtest = pd.concat([Xtest, bonus], axis=1)\n",
      "    both = change_vars(pd.concat([Xtrain, Xtest]))\n",
      "    # both.v56.fillna('AAAAAAAA', inplace=True)\n",
      "    # both.v56 = LabelEncoder().fit_transform(both.v56)\n",
      "    both = handle_nas(handle_categorical(both))\n",
      "    both.index = list(range(len(both)))\n",
      "    Xtrain = both.ix[:len(Xtrain)-1]\n",
      "    Xtest = both.ix[len(Xtrain):]\n",
      "else:\n",
      "    Xtrain = change_vars(Xtrain)\n",
      "    Xtrain = handle_categorical(Xtrain, ytrain)\n",
      "    Xtrain = handle_nas(Xtrain)\n",
      "    print(\"Processing time : \", datetime.now() - start)\n",
      "\n",
      "\n",
      "print('Fitting and predicting')\n",
      "start = datetime.now()\n",
      "if use_xgb:\n",
      "    if leaderboard:\n",
      "        pred = run_xgboost(Xtrain, ytrain, Xtest, None, leaderboard)\n",
      "        output_csv(ids, pred)\n",
      "    else:\n",
      "        run_xgboost(Xtrain, ytrain, leaderboard=leaderboard)\n",
      "# Split if we use RFC or sklearn. XGBoost handles it.\n",
      "else:\n",
      "    if not leaderboard:\n",
      "        Xtrain, Xtest, ytrain, ytest = train_test_split(Xtrain, ytrain, test_size=0.2)\n",
      "    pred = run_sklearn(Xtrain, ytrain, Xtest)\n",
      "    if leaderboard:\n",
      "        output_csv(ids, pred)\n",
      "    else:\n",
      "        print('Score :', log_loss(ytest, pred))\n",
      "print('Fitting and predicting time :', datetime.now() - start)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start processing.\n",
        "Processing time : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Will train until cv error hasn't decreased in 1 rounds.\n",
        "[0]\tcv-test-logloss:0.5406814000000001+0.005451398814983185\tcv-train-logloss:0.5301722+0.001085032792131189\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[1]\tcv-test-logloss:0.533336+0.005047670551848643\tcv-train-logloss:0.514008+0.002747406922900229\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[2]\tcv-test-logloss:0.5266493999999999+0.0047642730232428905\tcv-train-logloss:0.49883039999999995+0.002369441672630919\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[3]\tcv-test-logloss:0.5209474000000001+0.005608042603261844\tcv-train-logloss:0.4844828+0.0033532699503618897\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[4]\tcv-test-logloss:0.5164238+0.005055105672485979\tcv-train-logloss:0.4716448000000001+0.002880878366054353\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[5]\tcv-test-logloss:0.5129606000000001+0.005030022687821595\tcv-train-logloss:0.4603664+0.003284981132365915\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[6]\tcv-test-logloss:0.5100536+0.005600044056969535\tcv-train-logloss:0.450238+0.0032943787274689524\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[7]\tcv-test-logloss:0.5075596+0.005386127833611058\tcv-train-logloss:0.44097679999999995+0.0027416542743387597\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[8]\tcv-test-logloss:0.5045432+0.005444450657320714\tcv-train-logloss:0.43051019999999995+0.002459657244414354\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[9]\tcv-test-logloss:0.5024282+0.00554735004844656\tcv-train-logloss:0.421605+0.002679735285433997\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[10]\tcv-test-logloss:0.5008396+0.0056974056762705725\tcv-train-logloss:0.41383559999999997+0.0026119921592531676\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[11]\tcv-test-logloss:0.4993994+0.006161281964007176\tcv-train-logloss:0.405717+0.00267513468819796\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[12]\tcv-test-logloss:0.4982938+0.006271746244866711\tcv-train-logloss:0.3988782+0.002686375059443491\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[13]\tcv-test-logloss:0.496716+0.0061358744772037075\tcv-train-logloss:0.392238+0.0021482883419131475\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[14]\tcv-test-logloss:0.4956268+0.006353825789239121\tcv-train-logloss:0.38517080000000004+0.002118004759201451\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[15]\tcv-test-logloss:0.4946636+0.006523036366601053\tcv-train-logloss:0.379046+0.002579089994552345\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[16]\tcv-test-logloss:0.49404159999999997+0.006556514336139288\tcv-train-logloss:0.3739474+0.0021016156261314703\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[17]\tcv-test-logloss:0.4935772+0.006816523729878763\tcv-train-logloss:0.368135+0.0025471394151086488\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[18]\tcv-test-logloss:0.4929056+0.006826292393386026\tcv-train-logloss:0.36274360000000005+0.003368327098130477\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[19]\tcv-test-logloss:0.4924232+0.006804153978269453\tcv-train-logloss:0.35738020000000004+0.00326815956770778\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[20]\tcv-test-logloss:0.49213499999999993+0.006706727488127126\tcv-train-logloss:0.35265739999999995+0.003243176751273346\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[21]\tcv-test-logloss:0.49213779999999996+0.006824295374615601\tcv-train-logloss:0.34744080000000005+0.0029727458956325076\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0:00:04.696670\n",
        "Fitting and predicting\n",
        "Fitting and predicting time :"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0:00:46.602105\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Stopping. Best iteration:\n",
        "[20] cv-mean:0.49213499999999993\tcv-std:0.006706727488127126\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}