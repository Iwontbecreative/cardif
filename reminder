Avoid duplicate efforts

Things tried but failed/unconvincing:
- Add NA Count as a feature
- Replace NA with median/mean/mode
- Using KS to remove diff distribs accross train/test (no issues detected)
- Discarding variables with high correlation

Things to try:
- Remove features with low feature importance
- Remove outliers
- Ensemble stacking/bagging/averaging
- Improve RFC, ETC so they can be used
- Scaling down to 0.7611


For GBT, mean prediction is 0.77 so we're overshooting by just a little bit
if we accept the hypothesis that the means are the same.

Warning: Currently small changes such as variable scaling are impossible to
test as the differences might all be seed-related. One way to test those
would be to run CV but this is currently way too slow. They are 2 possible
fixes : run in a faster computer or use less variables for testing.
Note: We currently use XGB CV with 150 iter to test for this.
